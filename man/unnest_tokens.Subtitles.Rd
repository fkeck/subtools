% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unnest_tokens.R
\name{unnest_tokens.Subtitles}
\alias{unnest_tokens.Subtitles}
\title{Split a column into tokens}
\usage{
\method{unnest_tokens}{Subtitles}(tbl, output, input, token = "words",
  format = c("text", "man", "latex", "html", "xml"),
  time.remapping = TRUE, to_lower = TRUE, drop = TRUE,
  collapse = NULL, ...)
}
\arguments{
\item{tbl}{A data frame}

\item{output}{Output column to be created as string or symbol.}

\item{input}{Input column that gets split as string or symbol.

  The output/input arguments are passed by expression and support
  \link[rlang]{quasiquotation}; you can unquote strings and symbols.}

\item{token}{Unit for tokenizing, or a custom tokenizing function. Built-in
options are "words" (default), "characters", "character_shingles", "ngrams",
"skip_ngrams", "sentences", "lines", "paragraphs", "regex", "tweets"
(tokenization by word that preserves usernames, hashtags, and URLS ), and
"ptb" (Penn Treebank). If a function, should take a character vector and
return a list of character vectors of the same length.}

\item{format}{Either "text", "man", "latex", "html", or "xml". If not text,
this uses the hunspell tokenizer, and can tokenize only by "word"}

\item{time.remapping}{a logical. If \code{TRUE} (default), subtitle timecodes are recalculated
to take into account the split of the input column.}

\item{to_lower}{Whether to convert tokens to lowercase. If tokens include
URLS (such as with \code{token = "tweets"}), such converted URLs may no
longer be correct.}

\item{drop}{Whether original input column should get dropped. Ignored
if the original input and new output column have the same name.}

\item{collapse}{Whether to combine text with newlines first in case tokens
(such as sentences or paragraphs) span multiple lines. If NULL, collapses
when token method is "ngrams", "skip_ngrams", "sentences", "lines",
"paragraphs", or "regex".}

\item{...}{Extra arguments passed on to \link[tokenizers]{tokenizers}, such
as \code{strip_punct} for "words" and "tweets", \code{n} and \code{k} for
"ngrams" and "skip_ngrams", \code{strip_url} for "tweets", and
\code{pattern} for "regex".}
}
\value{
A tibble.
}
\description{
This function extends unnest_tokens to Subtitles objects. The main difference with the data.frame method
is the possibility to perform timecode remapping according to the split of the input column.
}
\examples{
f <- system.file("extdata", "ex_webvtt.vtt", package = "subtools")
s <- read_subtitles(f)

require(tidytext)
unnest_tokens(s, Word, Text_content)
unnest_tokens(s, Word, Text_content, token = "lines")
}
